{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic\n",
    "from collections import Counter\n",
    "import os\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import itertools\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "#NLTK Stopword List\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('arabic')\n",
    "\n",
    "#Gensim (LDA-Modelling)\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "#PDF-Reader\n",
    "import pdfplumber\n",
    "\n",
    "import pyLDAvis.gensim_models\n",
    "import xml.etree.ElementTree as ETree\n",
    "\n",
    "# plots\n",
    "from bidi.algorithm import get_display\n",
    "import arabic_reshaper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#file_path = 'read_pdfs'\n",
    "file_path = 'Al-Naba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def prepare_comp_corpus(corpus_path=\"Alittihad_XML_utf_8/Alittihad_utf_8.xml\"):\n",
    "    # read xml\n",
    "    parser = ETree.XMLParser(encoding='UTF-8')\n",
    "    tree = ETree.parse(corpus_path, parser=parser)\n",
    "    xroot = tree.getroot()\n",
    "\n",
    "    # extract texts\n",
    "    texts = []\n",
    "    for node in xroot:\n",
    "        texts.append(node.find(\"Text\").text)\n",
    "\n",
    "    # check for text duplicates\n",
    "    unique_texts_with_none = list(set(texts))\n",
    "    unique_texts = []\n",
    "    for ele in filter(None, unique_texts_with_none): # remove None\n",
    "        unique_texts.append(ele)\n",
    "\n",
    "    # join all texts and do naive tokenization\n",
    "    words = ' '.join(unique_texts).split()\n",
    "\n",
    "    # keep only unique words\n",
    "    words = list(set(words))\n",
    "    print('Unique words: ' + str(len(words)))\n",
    "\n",
    "    # remove punct\n",
    "    for pattern in [r\"\\W\", r\"\\d\"]:#[r\"\\[\", r\"\\]\", r\"\\(\", r\"\\)\", r\"\\|\", r\"/\", r\"\\.\", r\"\\:\", r\"\\«\", r\"\\\"\", r\"\\»\", r\"\\'\", r\"\\d\", r\"\\%\"]: \n",
    "        words = [re.sub(pattern, \"\", word) for word in words]\n",
    "    return words\n",
    "\n",
    "def get_text(file_path):\n",
    "    data_list = []\n",
    "    pages_list = []\n",
    "    file_list = []\n",
    "\n",
    "    for index, filename in enumerate(os.listdir(file_path)):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            with pdfplumber.open(join(file_path,filename)) as stream_pdf:\n",
    "                pages_content = [i.extract_text() for i in stream_pdf.pages]\n",
    "                number_pages = len(pages_content)\n",
    "                data_list.extend(pages_content)\n",
    "                pages_list.extend(i+1 for i in range(number_pages))\n",
    "                file_list.extend([filename] * number_pages)\n",
    "                \n",
    "    data_df = pd.DataFrame({'content': data_list,\n",
    "                            'page': pages_list,\n",
    "                            'file': file_list,\n",
    "                            'date': np.nan})\n",
    "    return data_df\n",
    "\n",
    "# add handselected words to the comparence dict\n",
    "def load_handselected_words(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        read_in = f.readlines()\n",
    "    res = []\n",
    "    for entry in read_in:\n",
    "        if ',' in entry:\n",
    "            res.append(entry.split(',')[0].split('\\\\')[0])\n",
    "    return res\n",
    "\n",
    "#283 issues, missing issue no. 85\n",
    "def insert_date(df, start_date=datetime.date(2015, 10, 16)):\n",
    "    res_list = []\n",
    "    for row_count in range(df['date'].shape[0]):\n",
    "        issue_no = int(df['file'][row_count][:-4].split('-')[-1]) # get issue no\n",
    "        if issue_no == 1:\n",
    "            res_list.append(start_date) # start equals date of first issue\n",
    "        else:\n",
    "            res_list.append(start_date + timedelta(days=(issue_no-1)*7)) # add the passed days to the start date using the issue number\n",
    "    df['date'] = res_list\n",
    "    return df\n",
    "\n",
    "def preproc_pagewise(data_df, comp_list, all_words_to_be_processed):\n",
    "    # preprocess all sentences pagewise\n",
    "    pages = []\n",
    "    for issue in set(data_df['file'].values):\n",
    "        for page in data_df['content'][data_df['file'] == issue].values:\n",
    "            page_dat = [''.join(page)]\n",
    "            \n",
    "            # Remove Emails\n",
    "            page_dat = [re.sub(r'\\S*@\\S*\\s?', '', sent) for sent in page_dat]\n",
    "            \n",
    "            # Remove new line characters\n",
    "            page_dat = [re.sub(r'\\s+', ' ', sent) for sent in page_dat]\n",
    "            page_dat = [re.sub(r'\\n', ' ', sent) for sent in page_dat]\n",
    "\n",
    "            # Remove distracting single quotes\n",
    "            page_dat = [re.sub(r\"\\'\", \"\", sent) for sent in page_dat]\n",
    "            page_dat = [re.sub(r\"/\", \"\", sent) for sent in page_dat]\n",
    "\n",
    "            # Remove Numbers\n",
    "            for i in range(10):\n",
    "                page_dat = [re.sub(str(i), \"\", sent) for sent in page_dat]\n",
    "\n",
    "            # Remove Brackets\n",
    "            reg_pat = [ r\"\\[\", r\"\\]\", r\"\\(\", r\"\\)\", r\"\\|\", r\"/\", r\"\\.\", r\"\\:\" ]\n",
    "            for pattern in reg_pat:\n",
    "                page_dat = [re.sub(pattern, \"\", sent) for sent in page_dat]\n",
    "\n",
    "            processed_words_page = remove_stopwords(invert_words(page_dat))[0] # '[0]' to flatten result list of remove_stopwords function\n",
    "            \n",
    "            pages.append([word for word in processed_words_page if (word in comp_list) and (word in all_words_to_be_processed)]) #  check which words are in both lists\n",
    "    return pages\n",
    "\n",
    "def invert_words(data_words_nostops):\n",
    "    data_words_nostops_inverted = []\n",
    "    for i in data_words_nostops:\n",
    "        #print(i)\n",
    "        #temp = [j[::-1] for j in i]\n",
    "        #print(temp)\n",
    "        #print([i for i in reversed(temp)])\n",
    "        temp = [i for i in reversed(i)] # reversed\n",
    "        #print(''.join(temp))\n",
    "        temp = ''.join(temp)\n",
    "        #print(temp)\n",
    "        data_words_nostops_inverted.append(temp)\n",
    "    return data_words_nostops_inverted\n",
    "\n",
    "def grammization(data_words):\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=8, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "    return bigram, trigram, bigram_mod, trigram_mod\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization, rm words smaller than 3 chars\n",
    "def remove_stopwords(texts):\n",
    "\n",
    "    # def flatten(lis): # helper to flatten results\n",
    "    #     return [item for sublist in lis for item in sublist if item != '']\n",
    "\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words and len(word) > 2] for doc in texts]\n",
    "\n",
    "# unused\n",
    "# def make_bigrams(texts):\n",
    "#     return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# unused\n",
    "# def make_trigrams(texts):\n",
    "#     return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "\n",
    "def gensim_prep(word_list):\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(word_list)\n",
    "    id2word.filter_extremes(no_below=1, keep_n=75000)\n",
    "    print('Length dictionary: ' + str(len(id2word)))\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in word_list]\n",
    "\n",
    "    return id2word, corpus\n",
    "\n",
    "def get_lda(corpus, id2word, num_topics, n_jobs=3, passes=50, chunksize=100, save=False, model_name='myldamodel', save_path=r'C:\\Users\\kantg\\Documents\\Uni\\nlp_arabic\\saved_models'):\n",
    "\n",
    "    lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus, \n",
    "                                        id2word=id2word,\n",
    "                                        num_topics=num_topics,\n",
    "                                        random_state=100,\n",
    "                                        chunksize=chunksize,\n",
    "                                        workers=n_jobs, \n",
    "                                        passes=passes,\n",
    "                                        per_word_topics=True)\n",
    "\n",
    "    try:\n",
    "        if save:\n",
    "            # Save model to disk.\n",
    "            #temp_file = datapath(model_name)\n",
    "            save_path = save_path + '\\\\' + model_name\n",
    "            print(save_path)\n",
    "            lda_model.save(save_path)\n",
    "    except:\n",
    "        print('did not save LDA model!')\n",
    "        \n",
    "    return lda_model\n",
    "\n",
    "def visu(lda_model, corpus, id2word, name):\n",
    "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    pyLDAvis.save_html(vis, name + '.html')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# We need to redo the preprocessing steps with the base data to get the tokens pagewise:\n",
    "\n",
    "# load most occuring words\n",
    "with open('most_occuring_words_modified.txt', 'r', encoding='utf-8') as f:\n",
    "    most_occuring_words_mod = f.readlines()\n",
    "most_occuring_words_mod = [x.strip() for x in most_occuring_words_mod] # rm newline\n",
    "most_occuring_words_mod = [x.split(sep=',')[0] for x in most_occuring_words_mod if x != ''] # rm non-needed string parts and empty strings\n",
    "\n",
    "# load compareance list\n",
    "with open('comparison_list_alittihad.pkl', 'rb') as f:\n",
    "    comp_list = pickle.load(f)\n",
    "\n",
    "# load talibs approved list of real words\n",
    "with open('all_words_to_be_processed_edited_by_TA.txt', 'r', encoding='utf-8') as f:\n",
    "    all_words_to_be_processed = f.readlines()\n",
    "    all_words_to_be_processed = [word.replace('\\n','') for word in all_words_to_be_processed if (word != '\\n')]\n",
    "\n",
    "# preprocess data\n",
    "data_df = get_text(file_path)\n",
    "data_df = insert_date(data_df) \n",
    "data_df = data_df.dropna(subset=['content'])\n",
    "data_words_nostops_full_comp_plus_most_occ = preproc_pagewise(data_df, comp_list, all_words_to_be_processed)\n",
    "data_df.reset_index(drop=True, inplace = True)\n",
    "data_df['cleaned_tokens'] = pd.Series(data_words_nostops_full_comp_plus_most_occ) # append pagewise tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>page</th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ـه 1440 ىلولأا ىدامج 25 سيمخلا ا ةرشاعلا ةنسلا...</td>\n",
       "      <td>1</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[تشاد, السويداء, لهالك, بحيرة, تلول, الصفا, بر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3\\nةيحاتتفلاا\\n167 ددعلا\\nـه 1440 ىلولأا ىدامج...</td>\n",
       "      <td>3</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[يرد, كيد, صفر, أمامهم, الفضل, والسيطرة, نقاطه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4\\n167 ددعلا راــبخأ\\nـه 1440 ىلولأا ىدامج 25 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[لتدمريها, وفجروها, تقل, الحسكة, الشدادي, زرع,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5\\nراــبخأ 167 ددعلا\\nـه 1440 ىلولأا ىدامج 25 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[الطيانة, وإيقاع, مدرسة, منطق, دوار, العتال, ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6\\n167 ددعلا راــبخأ\\nـه 1440 ىلولأا ىدامج 25 ...</td>\n",
       "      <td>6</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[منديل, لتدمريها, كاسحة, ألغام, بيك, إمام, عسك...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>7\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦ ...</td>\n",
       "      <td>7</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[دخول, وحدهم, وحتى, الشط, تشكل, عادة, مأوى, وع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>8\\n٢٢٢ ددعلا راــبخأ\\nـه 1441 ةرخلآا ىدامج ٢٦ ...</td>\n",
       "      <td>8</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[زمان, ومكان, يقيم, الوهاب, وحسن, رفيقا, فوجد,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦ ...</td>\n",
       "      <td>9</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[خطر, خططهم, الهجومية, بناء, جهاز, هاتف, يتصل,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>10\\n٢٢٢ ددعلا تلااقم\\nـه 1441 ةرخلآا ىدامج ٢٦ ...</td>\n",
       "      <td>10</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[وعدنا, الخطاب, ونحن, الجليل, خطاب, العزة, الص...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>11\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦...</td>\n",
       "      <td>11</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[خارج, الدويل, لحركة, حماس, لحماية, يحق, التصو...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3422 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  page  \\\n",
       "0     ـه 1440 ىلولأا ىدامج 25 سيمخلا ا ةرشاعلا ةنسلا...     1   \n",
       "1     3\\nةيحاتتفلاا\\n167 ددعلا\\nـه 1440 ىلولأا ىدامج...     3   \n",
       "2     4\\n167 ددعلا راــبخأ\\nـه 1440 ىلولأا ىدامج 25 ...     4   \n",
       "3     5\\nراــبخأ 167 ددعلا\\nـه 1440 ىلولأا ىدامج 25 ...     5   \n",
       "4     6\\n167 ددعلا راــبخأ\\nـه 1440 ىلولأا ىدامج 25 ...     6   \n",
       "...                                                 ...   ...   \n",
       "3417  7\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦ ...     7   \n",
       "3418  8\\n٢٢٢ ددعلا راــبخأ\\nـه 1441 ةرخلآا ىدامج ٢٦ ...     8   \n",
       "3419  9\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦ ...     9   \n",
       "3420  10\\n٢٢٢ ددعلا تلااقم\\nـه 1441 ةرخلآا ىدامج ٢٦ ...    10   \n",
       "3421  11\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦...    11   \n",
       "\n",
       "                                                   file        date  \\\n",
       "0     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "1     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "2     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "3     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "4     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "...                                                 ...         ...   \n",
       "3417    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "3418    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "3419    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "3420    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "3421    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "\n",
       "                                         cleaned_tokens  \n",
       "0     [تشاد, السويداء, لهالك, بحيرة, تلول, الصفا, بر...  \n",
       "1     [يرد, كيد, صفر, أمامهم, الفضل, والسيطرة, نقاطه...  \n",
       "2     [لتدمريها, وفجروها, تقل, الحسكة, الشدادي, زرع,...  \n",
       "3     [الطيانة, وإيقاع, مدرسة, منطق, دوار, العتال, ت...  \n",
       "4     [منديل, لتدمريها, كاسحة, ألغام, بيك, إمام, عسك...  \n",
       "...                                                 ...  \n",
       "3417  [دخول, وحدهم, وحتى, الشط, تشكل, عادة, مأوى, وع...  \n",
       "3418  [زمان, ومكان, يقيم, الوهاب, وحسن, رفيقا, فوجد,...  \n",
       "3419  [خطر, خططهم, الهجومية, بناء, جهاز, هاتف, يتصل,...  \n",
       "3420  [وعدنا, الخطاب, ونحن, الجليل, خطاب, العزة, الص...  \n",
       "3421  [خارج, الدويل, لحركة, حماس, لحماية, يحق, التصو...  \n",
       "\n",
       "[3422 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "enemy_groups = {\n",
    "    'far_enemies':['نصارى','صليبيون', 'صليبيين', 'صليبي', 'يهود', 'يهودي', 'يهودية'],\n",
    "    'near_enemies':['نصيريون', 'نصيريين', 'نصيري', 'كرد', 'أكراد', 'شيعة', 'روافض', 'رافضة', 'شيعي', 'رافضي', 'كردي', 'يزيديون', 'يزيديين', 'ايزيدي', 'ايزيديون', 'ايزيديين', 'يزيدي', 'ايزيدي']\n",
    "}\n",
    "\n",
    "# additional enemy-related words\n",
    "with open('List of enemies and related words.txt', 'r', encoding='utf-8') as f:\n",
    "    enemy_related_words = f.readlines()\n",
    "    enemy_related_words = [x.strip() for x in enemy_related_words] # rm newline\n",
    "    enemy_related_words = [x.split(sep=',')[0] for x in enemy_related_words if x not in ['#Far Enemies', '#Near Enemies', '#Useful words']] # rm headlines\n",
    "    \n",
    "# once more, all enemies in one single list\n",
    "all_enemies = enemy_groups['far_enemies'] + enemy_groups['near_enemies']\n",
    "all_enemies_plus_related_words = all_enemies + enemy_related_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# count occurrences of words\n",
    "def count_enemy_mentions_per_page(token_list, enemy_list):\n",
    "    res = Counter()\n",
    "    for enemy_word in enemy_list:\n",
    "        res[enemy_word] = token_list.count(enemy_word)\n",
    "    return [res, sum(res.values())] # return the counter and the sum of all enemy_words occurrences\n",
    "\n",
    "data_df['enemy_words_occurrences_counter'], data_df['enemy_words_occurrences_sum'] = zip(*data_df['cleaned_tokens'].apply(lambda x: count_enemy_mentions_per_page(x, all_enemies_plus_related_words)))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>page</th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "      <th>enemy_words_occurrences_counter</th>\n",
       "      <th>enemy_words_occurrences_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ـه 1440 ىلولأا ىدامج 25 سيمخلا ا ةرشاعلا ةنسلا...</td>\n",
       "      <td>1</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[تشاد, السويداء, لهالك, بحيرة, تلول, الصفا, بر...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3\\nةيحاتتفلاا\\n167 ددعلا\\nـه 1440 ىلولأا ىدامج...</td>\n",
       "      <td>3</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[يرد, كيد, صفر, أمامهم, الفضل, والسيطرة, نقاطه...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4\\n167 ددعلا راــبخأ\\nـه 1440 ىلولأا ىدامج 25 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[لتدمريها, وفجروها, تقل, الحسكة, الشدادي, زرع,...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5\\nراــبخأ 167 ددعلا\\nـه 1440 ىلولأا ىدامج 25 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[الطيانة, وإيقاع, مدرسة, منطق, دوار, العتال, ت...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6\\n167 ددعلا راــبخأ\\nـه 1440 ىلولأا ىدامج 25 ...</td>\n",
       "      <td>6</td>\n",
       "      <td>the-islamic-state-22al-nabacc84e28099-newslett...</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>[منديل, لتدمريها, كاسحة, ألغام, بيك, إمام, عسك...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>7\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦ ...</td>\n",
       "      <td>7</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[دخول, وحدهم, وحتى, الشط, تشكل, عادة, مأوى, وع...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>8\\n٢٢٢ ددعلا راــبخأ\\nـه 1441 ةرخلآا ىدامج ٢٦ ...</td>\n",
       "      <td>8</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[زمان, ومكان, يقيم, الوهاب, وحسن, رفيقا, فوجد,...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦ ...</td>\n",
       "      <td>9</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[خطر, خططهم, الهجومية, بناء, جهاز, هاتف, يتصل,...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>10\\n٢٢٢ ددعلا تلااقم\\nـه 1441 ةرخلآا ىدامج ٢٦ ...</td>\n",
       "      <td>10</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[وعدنا, الخطاب, ونحن, الجليل, خطاب, العزة, الص...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>11\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦...</td>\n",
       "      <td>11</td>\n",
       "      <td>The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>[خارج, الدويل, لحركة, حماس, لحماية, يحق, التصو...</td>\n",
       "      <td>{'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3422 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  page  \\\n",
       "0     ـه 1440 ىلولأا ىدامج 25 سيمخلا ا ةرشاعلا ةنسلا...     1   \n",
       "1     3\\nةيحاتتفلاا\\n167 ددعلا\\nـه 1440 ىلولأا ىدامج...     3   \n",
       "2     4\\n167 ددعلا راــبخأ\\nـه 1440 ىلولأا ىدامج 25 ...     4   \n",
       "3     5\\nراــبخأ 167 ددعلا\\nـه 1440 ىلولأا ىدامج 25 ...     5   \n",
       "4     6\\n167 ددعلا راــبخأ\\nـه 1440 ىلولأا ىدامج 25 ...     6   \n",
       "...                                                 ...   ...   \n",
       "3417  7\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦ ...     7   \n",
       "3418  8\\n٢٢٢ ددعلا راــبخأ\\nـه 1441 ةرخلآا ىدامج ٢٦ ...     8   \n",
       "3419  9\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦ ...     9   \n",
       "3420  10\\n٢٢٢ ددعلا تلااقم\\nـه 1441 ةرخلآا ىدامج ٢٦ ...    10   \n",
       "3421  11\\nراــبخأ ٢٢٢ ددعلا\\nـه 1441 ةرخلآا ىدامج ٢٦...    11   \n",
       "\n",
       "                                                   file        date  \\\n",
       "0     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "1     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "2     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "3     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "4     the-islamic-state-22al-nabacc84e28099-newslett...  2018-12-21   \n",
       "...                                                 ...         ...   \n",
       "3417    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "3418    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "3419    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "3420    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "3421    The-Islamic-State-—-al-Nabā’-Newsletter-222.pdf  2020-01-10   \n",
       "\n",
       "                                         cleaned_tokens  \\\n",
       "0     [تشاد, السويداء, لهالك, بحيرة, تلول, الصفا, بر...   \n",
       "1     [يرد, كيد, صفر, أمامهم, الفضل, والسيطرة, نقاطه...   \n",
       "2     [لتدمريها, وفجروها, تقل, الحسكة, الشدادي, زرع,...   \n",
       "3     [الطيانة, وإيقاع, مدرسة, منطق, دوار, العتال, ت...   \n",
       "4     [منديل, لتدمريها, كاسحة, ألغام, بيك, إمام, عسك...   \n",
       "...                                                 ...   \n",
       "3417  [دخول, وحدهم, وحتى, الشط, تشكل, عادة, مأوى, وع...   \n",
       "3418  [زمان, ومكان, يقيم, الوهاب, وحسن, رفيقا, فوجد,...   \n",
       "3419  [خطر, خططهم, الهجومية, بناء, جهاز, هاتف, يتصل,...   \n",
       "3420  [وعدنا, الخطاب, ونحن, الجليل, خطاب, العزة, الص...   \n",
       "3421  [خارج, الدويل, لحركة, حماس, لحماية, يحق, التصو...   \n",
       "\n",
       "                        enemy_words_occurrences_counter  \\\n",
       "0     {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "1     {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "2     {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "3     {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "4     {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "...                                                 ...   \n",
       "3417  {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "3418  {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "3419  {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "3420  {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "3421  {'نصارى': 0, 'صليبيون': 0, 'صليبيين': 0, 'صليب...   \n",
       "\n",
       "      enemy_words_occurrences_sum  \n",
       "0                               0  \n",
       "1                               1  \n",
       "2                               0  \n",
       "3                               0  \n",
       "4                               2  \n",
       "...                           ...  \n",
       "3417                            0  \n",
       "3418                            0  \n",
       "3419                            0  \n",
       "3420                            0  \n",
       "3421                           10  \n",
       "\n",
       "[3422 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length dictionary: 14195\n"
     ]
    }
   ],
   "source": [
    "# Choose the pages with more than X-occurrences of enemy_related keywords and prepare the tokens for LDA:\n",
    "pagewise_for_lda_chosen_tokens = data_df[data_df['enemy_words_occurrences_sum'] > 3]['cleaned_tokens']\n",
    "id2word, corpus = gensim_prep(pagewise_for_lda_chosen_tokens)\n",
    "\n",
    "save_dict = {'data_df': data_df, 'pagewise_for_lda_chosen_tokens': pagewise_for_lda_chosen_tokens, 'id2word': id2word, 'corpus': corpus }\n",
    "with open('save_dict_pagewise_full.pkl', 'wb') as f:\n",
    "    pickle.dump(save_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training model with 5 topics.\n",
      "C:\\Users\\kantg\\Documents\\Uni\\nlp_arabic\\saved_models\\5_topics_pagewise_full\n",
      "started training model with 8 topics.\n",
      "C:\\Users\\kantg\\Documents\\Uni\\nlp_arabic\\saved_models\\8_topics_pagewise_full\n",
      "started training model with 11 topics.\n",
      "C:\\Users\\kantg\\Documents\\Uni\\nlp_arabic\\saved_models\\11_topics_pagewise_full\n",
      "started training model with 14 topics.\n",
      "C:\\Users\\kantg\\Documents\\Uni\\nlp_arabic\\saved_models\\14_topics_pagewise_full\n",
      "started training model with 17 topics.\n",
      "C:\\Users\\kantg\\Documents\\Uni\\nlp_arabic\\saved_models\\17_topics_pagewise_full\n"
     ]
    }
   ],
   "source": [
    "# lda estimation\n",
    "\n",
    "for n in range(5,20,3):\n",
    "    print('started training model with ' + str(n) + ' topics.')\n",
    "    name = str(n) + '_topics_pagewise_full'\n",
    "    lda = get_lda(corpus, id2word, n_jobs=7, num_topics=n, save=True, model_name=name)\n",
    "    visu(lda, corpus, id2word, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\.conda\\envs\\arabic-nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_df', 'pagewise_for_lda_chosen_tokens', 'id2word', 'corpus'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('save_dict_pagewise_full.pkl', 'rb') as f:\n",
    "    load_dat = pickle.load(f)\n",
    "load_dat.keys()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d16b7831905752c68ba78b0fe6724dddb97984ed3c660333e8ee7e0c9644d8ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('arabic-nlp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
